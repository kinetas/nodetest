import time
import uuid
import json
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

# âœ… ë¸”ë¡œê·¸ ë³¸ë¬¸ ë‚´ìš© ì¶”ì¶œ í•¨ìˆ˜
def extract_blog_content(driver, url):
    try:
        driver.get(url)
        time.sleep(2)

        driver.switch_to.frame("mainFrame")
        time.sleep(1)

        try:
            content = driver.find_element(By.CSS_SELECTOR, "div.se-main-container").text.strip()
        except:
            content = driver.find_element(By.CSS_SELECTOR, "div#postViewArea").text.strip()

        driver.switch_to.default_content()
        return content
    except Exception as e:
        print(f"âŒ ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return ""

# âœ… ê²€ìƒ‰ í‚¤ì›Œë“œ ëª©ë¡
keywords = [
    ("ë¯¸ë¼í´ ëª¨ë‹ ë£¨í‹´", "ë£¨í‹´"),
    ("ìê¸°ê°œë°œ ë£¨í‹´", "ë£¨í‹´"),
    ("ìš´ë™ ë£¨í‹´", "ë£¨í‹´"),
    ("ìš”ë¦¬ ë£¨í‹´", "ë£¨í‹´")
]

# âœ… ì…€ë ˆë‹ˆì›€ ì„¤ì •
options = Options()
options.add_argument('--headless')
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')
options.add_argument('--disable-gpu')
options.add_argument('--window-size=1920x1080')

# âœ… ë“œë¼ì´ë²„ ì‹¤í–‰
print("ğŸ”„ í¬ë¡¬ ë“œë¼ì´ë²„ ì‹¤í–‰ ì¤‘...")
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

collected = []

for keyword, category in keywords:
    print(f"\nğŸ” '{keyword}' ë¸”ë¡œê·¸ ê²€ìƒ‰ ì‹œì‘...")
    search_url = f"https://section.blog.naver.com/Search/Post.naver?keyword={keyword}"
    driver.get(search_url)

    try:
        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "div.desc > a"))
        )
        cards = driver.find_elements(By.CSS_SELECTOR, "div.desc > a")
        links = [card.get_attribute("href") for card in cards[:3]]
        print(f"ğŸ”— ìˆ˜ì§‘ëœ ë¸”ë¡œê·¸ ë§í¬ ìˆ˜: {len(links)}")

        for link in links:
            content = extract_blog_content(driver, link)
            if content:
                collected.append({
                    "id": str(uuid.uuid4()),
                    "document": content[:2000],
                    "metadata": {
                        "tag": keyword,
                        "category": category,
                        "source": link
                    }
                })
            time.sleep(3)  # ë”œë ˆì´ ì¶”ê°€

    except Exception as e:
        print(f"âš  ë¸”ë¡œê·¸ ë§í¬ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

# âœ… ì¢…ë£Œ ë° ì €ì¥
driver.quit()

with open("blog_data.json", "w", encoding="utf-8") as f:
    json.dump(collected, f, ensure_ascii=False, indent=2)

print(f"\nâœ… {len(collected)}ê°œì˜ ë¸”ë¡œê·¸ ë¬¸ì„œ ì €ì¥ ì™„ë£Œ â†’ blog_data.json")