import json
from langchain_community.vectorstores import Chroma
from langchain.schema import Document
from langchain_ollama import OllamaEmbeddings
from langchain_chroma import Chroma
from dotenv import load_dotenv
import os

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# âœ… JSON íŒŒì¼ ê²½ë¡œ
json_file = "naver_blog_data.json"

# âœ… Chroma ì„¤ì •
persist_directory = "/chroma/chroma"
embedding = OllamaEmbeddings(base_url="http://ollama:11434", model="llama3")
db = Chroma(persist_directory=persist_directory, embedding_function=embedding)

# âœ… ê¸°ì¡´ ë¬¸ì„œ ì‚­ì œ (ì´ˆê¸°í™”)
existing = db.get()
ids = existing["ids"]
if ids:
    db.delete(ids=ids)
    print(f"ğŸ§¹ ê¸°ì¡´ ë¬¸ì„œ {len(ids)}ê°œ ì‚­ì œ ì™„ë£Œ")

# âœ… JSON ë¶ˆëŸ¬ì˜¤ê¸°
with open(json_file, "r", encoding="utf-8") as f:
    data = json.load(f)["documents"]

# âœ… ë¬¸ì„œ ê°€ê³µ (ìš”ì•½ ì—†ìŒ)
processed_docs = []

for item in data:
    full_text = item["document"]
    metadata = item["metadata"]

    doc = Document(page_content=full_text, metadata=metadata)
    processed_docs.append(doc)

# âœ… Chroma DBì— ì¶”ê°€
if processed_docs:
    db.add_documents(processed_docs)
    print(f"âœ… {len(processed_docs)}ê°œì˜ ë¬¸ì„œê°€ DBì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
else:
    print("ğŸš¨ ì¶”ê°€í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
