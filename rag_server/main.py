# from fastapi import FastAPI
# from fastapi.responses import JSONResponse, FileResponse
# from fastapi.staticfiles import StaticFiles
# from pydantic import BaseModel
# from langchain_ollama import OllamaLLM
# from langchain_chroma import Chroma
# from langchain_ollama import OllamaEmbeddings
# from langchain.chains import RetrievalQA


# app = FastAPI()

# embedding = OllamaEmbeddings(base_url="http://ollama:11434", model="llama3")
# db = Chroma(persist_directory="/chroma/chroma", embedding_function=embedding)  # ê³µìœ  ë³¼ë¥¨ ê²½ë¡œ
# retriever = db.as_retriever()

# llm = OllamaLLM(base_url="http://ollama:11434", model="llama3")  # Ollama ëª¨ë¸ ì‚¬ìš©

# qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

# class RAGRequest(BaseModel):
#     category: str

# @app.post("/recommend")
# async def recommend(req: RAGRequest):
#     query = f"{req.category} ì˜¤ëŠ˜ í•´ë³¼ ë§Œí•œ ë¯¸ì…˜ 2ê°€ì§€ ì¶”ì²œí•´ì¤˜. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì§§ê²Œ ë§í•´ì¤˜."
#     response = qa.run(query)
#     return {"message": response}

# @app.get("/documents")
# async def get_documents():
#     try:
#         data = db.get()
#         documents_info = []
#         for i in range(len(data['ids'])):
#             doc = {
#                 "id": data['ids'][i],
#                 "document": data['documents'][i],
#                 "metadata": data['metadatas'][i]
#             }
#             documents_info.append(doc)
#         return JSONResponse(content={"documents": documents_info})
#     except Exception as e:
#         return JSONResponse(status_code=500, content={"error": str(e)})

# # ì •ì  íŒŒì¼ ì„œë¹™ ì„¤ì •
# app.mount("/static", StaticFiles(directory="static"), name="static")

# @app.get("/")
# def serve_index():
#     return FileResponse("static/index.html")
# from fastapi import FastAPI
# from fastapi.responses import JSONResponse, FileResponse
# from fastapi.staticfiles import StaticFiles
# from pydantic import BaseModel
# import os
# import requests
# from dotenv import load_dotenv
# load_dotenv()

# app = FastAPI()

# class RAGRequest(BaseModel):
#     category: str

# GROQ_API_KEY = os.getenv("GROQ_API_KEY")
# GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"

# @app.post("/recommend")
# async def recommend(req: RAGRequest):
#     prompt = f"{req.category} ì˜¤ëŠ˜ í•´ë³¼ ë§Œí•œ ë¯¸ì…˜ 2ê°€ì§€ ì¶”ì²œí•´ì¤˜. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì§§ê²Œ ë§í•´ì¤˜."

#     headers = {
#         "Authorization": f"Bearer {GROQ_API_KEY}",
#         "Content-Type": "application/json"
#     }

#     body = {
#         "model": "llama3-8b-8192",
#         "messages": [
#             {"role": "user", "content": prompt}
#         ],
#         "temperature": 0.7
#     }

#     try:
#         response = requests.post(GROQ_API_URL, headers=headers, json=body)
#         response.raise_for_status()
#         result = response.json()
#         message = result["choices"][0]["message"]["content"]
#         return {"message": message}
#     except Exception as e:
#         return JSONResponse(status_code=500, content={"error": str(e)})

# # ì•„ë˜ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
# from langchain_chroma import Chroma
# from langchain_ollama import OllamaEmbeddings

# embedding = OllamaEmbeddings(base_url="http://ollama:11434", model="llama3")
# db = Chroma(persist_directory="/chroma/chroma", embedding_function=embedding)

# @app.get("/documents")
# async def get_documents():
#     try:
#         data = db.get()
#         documents_info = []
#         for i in range(len(data['ids'])):
#             doc = {
#                 "id": data['ids'][i],
#                 "document": data['documents'][i],
#                 "metadata": data['metadatas'][i]
#             }
#             documents_info.append(doc)
#         return JSONResponse(content={"documents": documents_info})
#     except Exception as e:
#         return JSONResponse(status_code=500, content={"error": str(e)})

# app.mount("/static", StaticFiles(directory="static"), name="static")

# @app.get("/")
# def serve_index():
#     return FileResponse("static/index.html")

# from fastapi import FastAPI
# from fastapi.responses import JSONResponse, FileResponse
# from fastapi.staticfiles import StaticFiles
# from pydantic import BaseModel
# import os
# import requests
# from dotenv import load_dotenv
# import time

# # âœ… .env íŒŒì¼ ë¡œë“œ
# load_dotenv()

# # âœ… Groq API ì„¤ì •
# GROQ_API_KEY = os.getenv("GROQ_API_KEY")
# GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"

# # âœ… FastAPI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
# app = FastAPI()

# # âœ… Pydantic ëª¨ë¸
# class RAGRequest(BaseModel):
#     category: str

# # âœ… Chroma (ë¬¸ì„œ ê²€ìƒ‰ìš©)
# from langchain_chroma import Chroma
# from langchain_ollama import OllamaEmbeddings

# # âš ï¸ OllamaëŠ” ì„ë² ë”©ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©ë¨ (ì„œë²„ í•„ìš”)
# embedding = OllamaEmbeddings(base_url="http://ollama:11434", model="llama3")
# db = Chroma(persist_directory="/chroma/chroma", embedding_function=embedding)

# # âœ… ì¶”ì²œ API (RAG êµ¬ì¡° ì ìš©)

# @app.post("/recommend")
# async def recommend(req: RAGRequest):
#     start_time = time.time()
#     query = f"{req.category} ì¹´í…Œê³ ë¦¬ì™€ ê´€ë ¨ëœ ì˜¤ëŠ˜ í•´ë³¼ ë§Œí•œ ë¯¸ì…˜ 2ê°€ì§€ ì¶”ì²œí•´ì¤˜. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì§§ê²Œ ë§í•´ì¤˜."

#     # 1. ë¬¸ì„œ ê²€ìƒ‰
#     docs_with_scores = db.similarity_search_with_score(query, k=4)

#     for doc, score in docs_with_scores:
#         print(f"ë¬¸ì„œ ìœ ì‚¬ë„ ì ìˆ˜: {score:.4f} / ë¬¸ì„œ: {doc.page_content[:30]}...")


#     # 2. ìœ ì‚¬ë„ í•„í„°ë§ (ì ìˆ˜ ë‚®ì„ìˆ˜ë¡ ê´€ë ¨ ìˆìŒ)
#     filtered_docs = [doc for doc, score in docs_with_scores if score < 0.53]
#     context = "\n\n".join([doc.page_content for doc in filtered_docs])

#     # 3. ë¬¸ì„œê°€ ì¶©ë¶„í•˜ë©´ RAG, ì•„ë‹ˆë©´ Groq ë‹¨ë…
#     is_rag = len(filtered_docs) >= 1 #and len(context) > 50

#     if is_rag:
#         final_prompt = (
#             f"ë‹¤ìŒì€ ì°¸ê³  ë¬¸ì„œì…ë‹ˆë‹¤:\n\n{context}\n\n"
#             f"ìœ„ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ í•œêµ­ì–´ë¡œ ì§§ê²Œ ì¶”ì²œí•´ì£¼ì„¸ìš”:\n\n{query}"
#         )
#     else:
#         final_prompt = query

#     # 4. Groq API í˜¸ì¶œ
#     headers = {
#         "Authorization": f"Bearer {GROQ_API_KEY}",
#         "Content-Type": "application/json"
#     }

#     body = {
#         "model": "llama3-8b-8192",
#         "messages": [{"role": "user", "content": final_prompt}],
#         "temperature": 0.7
#     }

#     try:
#         response = requests.post(GROQ_API_URL, headers=headers, json=body)
#         response.raise_for_status()
#         result = response.json()
#         message = result["choices"][0]["message"]["content"]
#         end_time = time.time()  # â±ï¸ ë ì‹œê°
#         elapsed_time = round(end_time - start_time, 2)  # ì†Œìˆ˜ 2ìë¦¬ê¹Œì§€
#         return {"message": message, "response_time_sec": elapsed_time}

#     except Exception as e:
#         return JSONResponse(status_code=500, content={"error": str(e)})

# RAGë§Œ ì‚¬ìš©ìš©

# @app.post("/recommend")
# async def recommend(req: RAGRequest):
#     start_time = time.time()
#     query = f"{req.category} ì˜¤ëŠ˜ í•´ë³¼ ë§Œí•œ ë¯¸ì…˜ 2ê°€ì§€ ì¶”ì²œí•´ì¤˜. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì§§ê²Œ ë§í•´ì¤˜."

#     headers = {
#         "Authorization": f"Bearer {GROQ_API_KEY}",
#         "Content-Type": "application/json"
#     }

#     body = {
#         "model": "llama3-8b-8192",
#         "messages": [{"role": "user", "content": query}],
#         "temperature": 0.7
#     }

#     try:
#         response = requests.post(GROQ_API_URL, headers=headers, json=body)
#         result = response.json()
#         message = result["choices"][0]["message"]["content"]
#         end_time = time.time()  # â±ï¸ ë ì‹œê°
#         elapsed_time = round(end_time - start_time, 2)  # ì†Œìˆ˜ 2ìë¦¬ê¹Œì§€
#         return {"message": message, "response_time_sec": elapsed_time}
#     except Exception as e:
#         return JSONResponse(status_code=500, content={"error": str(e)})

# CoT

# @app.post("/recommend")
# async def recommend(req: RAGRequest):
#     start_time = time.time()
#     user_input = f"{req.category} ì˜¤ëŠ˜ í•´ë³¼ ë§Œí•œ ë¯¸ì…˜ 2ê°€ì§€ ì¶”ì²œí•´ì¤˜."

#     cot_prompt = (
#         "ë„ˆëŠ” ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•´ ë¯¸ì…˜ì„ ì¶”ì²œí•˜ëŠ” AIì•¼. "
#         "ë¨¼ì € ì¹´í…Œê³ ë¦¬ë¥¼ ë¶„ì„í•˜ê³ , ê·¸ ì¹´í…Œê³ ë¦¬ì˜ íš¨ê³¼ë‚˜ íŠ¹ì§•ì„ í•œ ì¤„ë¡œ ìš”ì•½í•œ í›„, "
#         "ê·¸ì— ë§ëŠ” ë¯¸ì…˜ì„ 2ê°€ì§€ ì¶”ì²œí•´ì£¼ê³  ê·¸ê²Œ ì™œ ì¹´í…Œê³ ë¦¬ì˜ íš¨ê³¼ë‚˜ íŠ¹ì§•ê³¼ ë§ëŠ”ì§€ ê·¼ê±°ë¥¼ ë§í•´ì¤˜. ë°˜ë“œì‹œ ë‹¨ê³„ë³„ë¡œ ìƒê°í•˜ê³  ë§ˆì§€ë§‰ì— ìµœì¢… ê²°ê³¼ë¥¼ ì •ë¦¬í•´ì„œ í•œêµ­ì–´ë¡œ ë§í•´ì¤˜. \n\n"
#         f"ì‚¬ìš©ì ìš”ì²­: {user_input}"
#     )

#     headers = {
#         "Authorization": f"Bearer {GROQ_API_KEY}",
#         "Content-Type": "application/json"
#     }

#     body = {
#         "model": "llama3-8b-8192",
#         "messages": [{"role": "user", "content": cot_prompt}],
#         "temperature": 0.7
#     }

#     try:
#         response = requests.post(GROQ_API_URL, headers=headers, json=body)
#         result = response.json()
#         message = result["choices"][0]["message"]["content"]
#         end_time = time.time()  # â±ï¸ ë ì‹œê°
#         elapsed_time = round(end_time - start_time, 2)  # ì†Œìˆ˜ 2ìë¦¬ê¹Œì§€
#         return {"message": message, "response_time_sec": elapsed_time}
#     except Exception as e:
#         return JSONResponse(status_code=500, content={"error": str(e)})


# from fastapi import FastAPI
# from fastapi.responses import JSONResponse
# from pydantic import BaseModel
# from dotenv import load_dotenv
# import os, requests, re, json, time
# from langchain_chroma import Chroma
# from langchain_ollama import OllamaEmbeddings
# from fastapi.staticfiles import StaticFiles
# from fastapi.responses import FileResponse


# # í™˜ê²½ ì„¤ì •
# load_dotenv()
# GROQ_API_KEY = os.getenv("GROQ_API_KEY")
# GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"

# # FastAPI
# app = FastAPI()

# # ì„ë² ë”© & ë²¡í„° DB
# embedding = OllamaEmbeddings(base_url="http://ollama:11434", model="llama3")
# db = Chroma(persist_directory="/chroma/chroma", embedding_function=embedding)

# class ChatRequest(BaseModel):
#     category: str

# @app.post("/recommend")
# async def recommend(req: ChatRequest):
#     start_time = time.time()
#     query = f"{req.category} ì˜¤ëŠ˜ í•´ë³¼ ë§Œí•œ ë¯¸ì…˜ í•˜ë‚˜ ì¶”ì²œí•´ì¤˜."

#     # ğŸ” ë¬¸ì„œ ê²€ìƒ‰
#     docs_with_scores = db.similarity_search_with_score(query, k=4)
#     filtered_docs = [doc for doc, score in docs_with_scores if score < 0.53]
#     context = "\n\n".join([doc.page_content for doc in filtered_docs])

#     # ğŸ’¬ í”„ë¡¬í”„íŠ¸ ìƒì„±
#     if len(filtered_docs) >= 1:
#         # âœ… RAG ê¸°ë°˜ í”„ë¡¬í”„íŠ¸
#         final_prompt = (
#             "ë„ˆëŠ” ì‚¬ìš©ìì˜ ìš”ì²­ì„ ì°¸ê³  ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¯¸ì…˜ì„ ì¶”ì²œí•˜ëŠ” AIì•¼.ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ê³ , JSON ì™¸ì—ëŠ” ì•„ë¬´ ê²ƒë„ ì¶œë ¥í•˜ì§€ ë§ˆ.\n\n"
#             "message í•­ëª©ì€ ì‚¬ìš©ìì—ê²Œ ìì—°ìŠ¤ëŸ½ê³  ë¶€ë“œëŸ¬ìš´ ë¬¸ì¥ì´ì–´ì•¼ í•´. \n"
#             "ë‹¨, ì•„ë˜ëŠ” ì˜ˆì‹œì¼ ë¿ì´ë‹ˆ ì ˆëŒ€ë¡œ ë³µì‚¬í•˜ì§€ ë§ˆ:\n"
#             'ì˜ˆì‹œ: "ì±…ìƒ ì •ë¦¬ë¥¼ í•´ë³´ëŠ” ê±´ ì–´ë•Œìš”? ë§ˆìŒë„ í•¨ê»˜ ì •ë¦¬ë  ê±°ì˜ˆìš”."\n\n'
#             "ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´:\n"
#             '{\n'
#             '  "message": "ìì—°ì–´ ë¬¸ì¥",\n'
#             '  "category": "ì¹´í…Œê³ ë¦¬"\n'
#             "}\n\n"
#             f"ì°¸ê³  ë¬¸ì„œ:\n{context}\n\n"
#             f"ì‚¬ìš©ì ìš”ì²­: {query}"
#         )
#     else:
#         # âœ… CoT í”„ë¡¬í”„íŠ¸
#         final_prompt = (
#             "ë„ˆëŠ” ë¯¸ì…˜ ì¶”ì²œ AIì•¼. ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ê³ , JSON ì™¸ì—ëŠ” ì•„ë¬´ ê²ƒë„ ì¶œë ¥í•˜ì§€ ë§ˆ.\n\n"
#             "message í•­ëª©ì€ ì‚¬ìš©ìì˜ ìš”ì²­ì— ë§ëŠ” ì¹´í…Œê³ ë¦¬ë¥¼ ë¶„ì„í•˜ê³  ê·¸ ì¹´í…Œê³ ë¦¬ê°€ ì–´ë–¤ íŠ¹ì§•ê³¼ íš¨ê³¼ê°€ ìˆëŠ”ì§€ ì•Œë ¤ì£¼ê³  ê·¸ì— ë”°ë¥¸ ë¯¸ì…˜ì„ ì¶”ì²œí•´ì£¼ê³  ê·¸ê²Œ ì™œ ì¹´í…Œê³ ë¦¬ì˜ íŠ¹ì§•ì´ë‚˜ íš¨ê³¼ì™€ ê´€ë ¨ìˆëŠ”ì§€ ê·¼ê±°ë¥¼ ìì—°ìŠ¤ëŸ½ê³  ë¶€ë“œëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ë§í•´ì¤˜. \n"
#             "ë‹¨, ì•„ë˜ëŠ” ì˜ˆì‹œì¼ ë¿ì´ë‹ˆ ì ˆëŒ€ë¡œ ë³µì‚¬í•˜ì§€ ë§ˆ:\n"
#             'ì˜ˆì‹œ: "ì±…ìƒ ì •ë¦¬ë¥¼ í•´ë³´ëŠ” ê±´ ì–´ë•Œìš”? ë§ˆìŒë„ í•¨ê»˜ ì •ë¦¬ë  ê±°ì˜ˆìš”."\n\n'
#             "category í•­ëª©ì€ í•´ë‹¹ ë¯¸ì…˜ì˜ ì¹´í…Œê³ ë¦¬ë¥¼ í•˜ë‚˜ë¡œ ìš”ì•½í•´ì„œ ë„£ì–´. (ì˜ˆ: ìš´ë™, ê°ì •ê´€ë¦¬, ìê¸°ê´€ë¦¬, ì§‘ì¤‘ ë“±)\n\n"
#             "ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´:\n"
#             '{\n'
#             '  "message": "ìì—°ì–´ ë¬¸ì¥",\n'
#             '  "category": "ì¹´í…Œê³ ë¦¬"\n'
#             "}\n\n"
#             f"ì‚¬ìš©ì ìš”ì²­: {query}"
#         )

#     # ğŸš€ Groq API í˜¸ì¶œ
#     headers = {
#         "Authorization": f"Bearer {GROQ_API_KEY}",
#         "Content-Type": "application/json"
#     }

#     body = {
#         "model": "llama3-8b-8192",
#         "messages": [{"role": "user", "content": final_prompt}],
#         "temperature": 0.7
#     }

#     try:
#         response = requests.post(GROQ_API_URL, headers=headers, json=body)
#         result = response.json()
#         content = result["choices"][0]["message"]["content"]

#         # ğŸ§  JSON íŒŒì‹±
#         json_match = re.search(r"\{.*\}", content, re.DOTALL)
#         if not json_match:
#             raise ValueError("ì‘ë‹µì—ì„œ JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
#         json_str = json_match.group(0).replace("'", '"')
#         parsed = json.loads(json_str)

#         parsed["response_time_sec"] = round(time.time() - start_time, 2)
#         return parsed

#     except json.JSONDecodeError as json_err:
#         return JSONResponse(status_code=500, content={
#             "error": "JSON íŒŒì‹± ì‹¤íŒ¨",
#             "detail": str(json_err),
#             "raw_content": content
#         })
#     except Exception as e:
#         return JSONResponse(status_code=500, content={"error": str(e)})

# # âœ… Chroma ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ í™•ì¸ìš©
# @app.get("/documents")
# async def get_documents():
#     try:
#         data = db.get()
#         documents_info = []
#         for i in range(len(data['ids'])):
#             doc = {
#                 "id": data['ids'][i],
#                 "document": data['documents'][i],
#                 "metadata": data['metadatas'][i]
#             }
#             documents_info.append(doc)
#         return JSONResponse(content={"documents": documents_info})
#     except Exception as e:
#         return JSONResponse(status_code=500, content={"error": str(e)})

# # âœ… ì •ì  íŒŒì¼ ì„œë¹™ (HTML í¬í•¨)
# app.mount("/static", StaticFiles(directory="static"), name="static")

# @app.get("/")
# def serve_index():
#     return FileResponse("static/index.html")


from fastapi import FastAPI
from fastapi.responses import JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from dotenv import load_dotenv
import os, requests, json, re, time
from bs4 import BeautifulSoup
from langchain_community.vectorstores import Chroma
# from langchain_ollama import OllamaEmbeddings
from langchain.embeddings import HuggingFaceEmbeddings
from langchain_community.embeddings import HuggingFaceEmbeddings

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë”©
load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"

# âœ… FastAPI ì´ˆê¸°í™”
app = FastAPI()
app.mount("/static", StaticFiles(directory="static"), name="static")

@app.get("/")
def serve_index():
    return FileResponse("static/index.html")

# âœ… ë²¡í„° DB ë° ì„ë² ë”© ì˜¬ë¼ë§ˆë²„ì „
# embedding = OllamaEmbeddings(base_url="http://ollama:11434", model="nomic-embed-text")
# db = Chroma(persist_directory="/chroma/chroma", embedding_function=embedding)

embedding = HuggingFaceEmbeddings(
    model_name="jhgan/ko-sroberta-multitask",
    model_kwargs={"device": "cpu"},
    encode_kwargs={"normalize_embeddings": True}
)
db = Chroma(persist_directory="/chroma/chroma", embedding_function=embedding)

# âœ… ë¸”ë¡œê·¸ ë³¸ë¬¸ í¬ë¡¤ë§ í•¨ìˆ˜
def crawl_naver_blog(url):
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        time.sleep(3) 
        res = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(res.text, "html.parser")

        iframe = soup.select_one("iframe#mainFrame")
        if iframe:
            iframe_url = "https://blog.naver.com" + iframe["src"]
            res2 = requests.get(iframe_url, headers=headers, timeout=10)
            soup2 = BeautifulSoup(res2.text, "html.parser")
            content_div = soup2.select_one("div.se-main-container")
            if content_div:
                return content_div.get_text("\n", strip=True)
        else:
            content_div = soup.select_one("div.se-main-container")
            if content_div:
                return content_div.get_text("\n", strip=True)
    except Exception as e:
        print("âŒ í¬ë¡¤ë§ ì‹¤íŒ¨:", e)
    return None

# âœ… API ëª¨ë¸
class ChatRequest(BaseModel):
    category: str

@app.post("/recommend")
async def recommend(req: ChatRequest):
    start_time = time.time()
    query = f"{req.category} ê´€ë ¨í•´ì„œ ì˜¤ëŠ˜ í•´ë³¼ ë§Œí•œ ë¯¸ì…˜ í•˜ë‚˜ ì¶”ì²œí•´ì¤˜."

    # ğŸ” RAG ê²€ìƒ‰
    docs_with_scores = db.similarity_search_with_score(query, k=4)
    print("ğŸ” ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼:")
    for i, (doc, score) in enumerate(docs_with_scores):
        content = doc.page_content or "(âš ï¸ ë‚´ìš© ì—†ìŒ)"
        try:
            preview = content[:100].replace('\n', ' ')
        except Exception as e:
            preview = f"(âš ï¸ ì¶œë ¥ ì‹¤íŒ¨: {e})"
        print(f"  {i+1}. ì ìˆ˜: {score:.4f}")
        print(f"     ìš”ì•½: {preview}")
        print(f"     ì¶œì²˜: {doc.metadata.get('source', '(ì—†ìŒ)')}")
    filtered_docs = [doc for doc, score in docs_with_scores if score < 1.1]

    if not filtered_docs:
        # âœ… fallback - CoT ë°©ì‹
        prompt = (
            "ë„ˆëŠ” ë¯¸ì…˜ ì¶”ì²œ AIì•¼. ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ê³ , JSON ì™¸ì—ëŠ” ì•„ë¬´ ê²ƒë„ ì¶œë ¥í•˜ì§€ ë§ˆ.\n"
            'message í•­ëª©ì€ ì‚¬ìš©ìì˜ ìš”ì²­ì— ë§ëŠ” ì¹´í…Œê³ ë¦¬ë¥¼ ë¶„ì„í•˜ê³  ê·¸ ì¹´í…Œê³ ë¦¬ê°€ ì–´ë–¤ íŠ¹ì§•ê³¼ íš¨ê³¼ê°€ ìˆëŠ”ì§€ ì•Œë ¤ì£¼ê³  ê·¸ì— ë”°ë¥¸ ë¯¸ì…˜ì„ ì¶”ì²œí•´ì£¼ê³  ê·¸ê²Œ ì™œ ì¹´í…Œê³ ë¦¬ì˜ íŠ¹ì§•ì´ë‚˜ íš¨ê³¼ì™€ ê´€ë ¨ìˆëŠ”ì§€ ê·¼ê±°ë¥¼ ìì—°ìŠ¤ëŸ½ê³  ë¶€ë“œëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ë¯¸ì…˜ì¶”ì²œì¤˜."\n\n'
            "category í•­ëª©ì€ í•´ë‹¹ ë¯¸ì…˜ì˜ ì¹´í…Œê³ ë¦¬ë¥¼ í•˜ë‚˜ë¡œ ìš”ì•½í•´ì„œ ë„£ì–´. (ì˜ˆ: ìš´ë™, ê°ì •ê´€ë¦¬, ìê¸°ê´€ë¦¬, ì§‘ì¤‘ ë“±)\n\n"
            "ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´:\n"
            '{\n'
            '  "message": "ìì—°ì–´ ë¬¸ì¥ìœ¼ë¡œëœ ë¯¸ì…˜ì¶”ì²œ",\n'
            '  "category": "ì¹´í…Œê³ ë¦¬"\n'
            "}\n\n"
            f"ì‚¬ìš©ì ìš”ì²­: {query}"
        )
    else:
        # âœ… ì²« ë¬¸ì„œì—ì„œ ë³¸ë¬¸ í¬ë¡¤ë§
        url = filtered_docs[0].metadata.get("source")
        blog_text = crawl_naver_blog(url) or ""
        print(f"\nğŸŒ ì„ íƒëœ ë¬¸ì„œ URL: {url}")

        blog_text = crawl_naver_blog(url) or ""
        print(f"ğŸ“„ í¬ë¡¤ë§ëœ ë¸”ë¡œê·¸ ë³¸ë¬¸ ê¸¸ì´: {len(blog_text)}ì")
        print(f"ğŸ“„ ë³¸ë¬¸ ì¼ë¶€:\n{blog_text[:500]}...\n")  # â† ì´ê²Œ í•µì‹¬!

        prompt = (
            "ë„ˆëŠ” ì‚¬ìš©ìì˜ ìš”ì²­ì„ ì°¸ê³  ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¯¸ì…˜ì„ ì¶”ì²œí•˜ëŠ” AIì•¼.\n"
            "ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ê³ , JSON ì™¸ì—ëŠ” ì•„ë¬´ ê²ƒë„ ì¶œë ¥í•˜ì§€ ë§ˆ.\n\n"
            "message í•­ëª©ì€ ì°¸ê³  ë¸”ë¡œê·¸ ë³¸ë¬¸ì˜ ë‚´ìš©ì„ ë³´ê³  ê·¸ê²Œ ì™œ ì¹´í…Œê³ ë¦¬ì™€ ì–´ë–¤ ê´€ë ¨ì´ ìˆê³  ì–´ë–¤ íš¨ê³¼ê°€ ìˆëŠ”ì§€ ë§í•´ì•¼ í•˜ë©° 4~5ì¤„ ì •ë„ ë˜ë„ë¡ ê¸¸ê³  ìì—°ìŠ¤ëŸ½ê³  ë¶€ë“œëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ë¯¸ì…˜ì„ ì¶”ì²œí•´ì•¼í•´.\n"
            # 'ì˜ˆì‹œ: "ì±…ìƒ ì •ë¦¬ë¥¼ í•´ë³´ëŠ” ê±´ ì–´ë•Œìš”? ë§ˆìŒë„ í•¨ê»˜ ì •ë¦¬ë  ê±°ì˜ˆìš”."\n\n'
            "ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´:\n"
            '{\n'
            '  "message": "ìì—°ì–´ ë¬¸ì¥ìœ¼ë¡œ ëœ ë¯¸ì…˜ì¶”ì²œ",\n'
            '  "category": "ì¹´í…Œê³ ë¦¬"\n'
            "}\n\n"
            f"ì°¸ê³  ë¸”ë¡œê·¸ ë³¸ë¬¸:\n{blog_text[:3000]}\n\n"
            f"ì‚¬ìš©ì ìš”ì²­: {query}"
        )

    # âœ… Groq API í˜¸ì¶œ
    headers = {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type": "application/json"
    }
    body = {
        "model": "llama3-8b-8192",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.7
    }

    try:
        response = requests.post(GROQ_API_URL, headers=headers, json=body)
        result = response.json()
        content = result["choices"][0]["message"]["content"]

        json_match = re.search(r"\{.*\}", content, re.DOTALL)
        if not json_match:
            raise ValueError("ì‘ë‹µì—ì„œ JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        parsed = json.loads(json_match.group(0).replace("'", '"'))
        parsed["response_time_sec"] = round(time.time() - start_time, 2)
        return parsed

    except Exception as e:
        return JSONResponse(status_code=500, content={"error": str(e)})

# âœ… ë””ë²„ê¹…ìš© ë¬¸ì„œ í™•ì¸ìš© API
@app.get("/documents")
async def get_documents():
    try:
        data = db.get()
        documents_info = []
        for i in range(len(data["ids"])):
            doc = {
                "id": data["ids"][i],
                "document": data["documents"][i],
                "metadata": data["metadatas"][i]
            }
            documents_info.append(doc)
        return JSONResponse(content={"documents": documents_info})
    except Exception as e:
        return JSONResponse(status_code=500, content={"error": str(e)})