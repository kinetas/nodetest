from fastapi import FastAPI
from fastapi.responses import JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from dotenv import load_dotenv
import os, requests, json, re, time, jwt
from fastapi import Request, HTTPException
from bs4 import BeautifulSoup
from langchain_community.vectorstores import Chroma
# from langchain_ollama import OllamaEmbeddings
from langchain.embeddings import HuggingFaceEmbeddings
from langchain_community.embeddings import HuggingFaceEmbeddings
import random

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë”©
load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"
USER_DB_API = "http://nodetest:3000/user-top-categories"
INTENT_API = "http://intent_server:8002/intent-classify"

SECRET_KEY = os.getenv("JWT_SECRET_KEY")
if not SECRET_KEY:
    raise RuntimeError("âŒ JWT_SECRET_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

ALGORITHM = "HS256"  # RS256ì´ ì•„ë‹ˆë¼ë©´ ì´ ê°’ ìœ ì§€

def extract_user_id_from_token(request: Request):
    auth_header = request.headers.get("Authorization")
    if not auth_header or not auth_header.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="í† í°ì´ ì—†ìŠµë‹ˆë‹¤")

    token = auth_header.split(" ")[1]
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        user_id = payload.get("userId")
        if not user_id:
            raise HTTPException(status_code=400, detail="user_id ì—†ìŒ")
        return user_id
    except jwt.ExpiredSignatureError:
        raise HTTPException(status_code=401, detail="í† í° ë§Œë£Œë¨")
    except jwt.InvalidTokenError:
        raise HTTPException(status_code=401, detail="ìœ íš¨í•˜ì§€ ì•Šì€ í† í°")

# âœ… FastAPI ì´ˆê¸°í™”
app = FastAPI()
app.mount("/static", StaticFiles(directory="static"), name="static")

@app.get("/")
def serve_index():
    return FileResponse("static/index.html")

# âœ… ë²¡í„° DB ë° ì„ë² ë”© ì˜¬ë¼ë§ˆë²„ì „
# embedding = OllamaEmbeddings(base_url="http://ollama:11434", model="nomic-embed-text")
# db = Chroma(persist_directory="/chroma/chroma", embedding_function=embedding)

embedding = HuggingFaceEmbeddings(
    model_name="jhgan/ko-sroberta-multitask",
    model_kwargs={"device": "cpu"},
    encode_kwargs={"normalize_embeddings": True}
)
db = Chroma(persist_directory="/chroma/chroma", embedding_function=embedding)

# class ChatRequest(BaseModel):
#     user_id: str
#     question: str

# âœ… ë¸”ë¡œê·¸ ë³¸ë¬¸ í¬ë¡¤ë§ í•¨ìˆ˜
def crawl_naver_blog(url):
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        time.sleep(3) 
        res = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(res.text, "html.parser")

        iframe = soup.select_one("iframe#mainFrame")
        if iframe:
            iframe_url = "https://blog.naver.com" + iframe["src"]
            res2 = requests.get(iframe_url, headers=headers, timeout=10)
            soup2 = BeautifulSoup(res2.text, "html.parser")
            content_div = soup2.select_one("div.se-main-container")
            if content_div:
                return content_div.get_text("\n", strip=True)
        else:
            content_div = soup.select_one("div.se-main-container")
            if content_div:
                return content_div.get_text("\n", strip=True)
    except Exception as e:
        print("âŒ í¬ë¡¤ë§ ì‹¤íŒ¨:", e)
    return None

# âœ… API ëª¨ë¸
class ChatRequest(BaseModel):
    category: str

# @app.post("/recommend")
# async def recommend(req: ChatRequest, request: Request):
#     start_time = time.time()
#     user_id = extract_user_id_from_token(request)
#     query = f"{req.category} ê´€ë ¨í•´ì„œ ì˜¤ëŠ˜ í•´ë³¼ ë§Œí•œ ë¯¸ì…˜ í•˜ë‚˜ ì¶”ì²œí•´ì¤˜."
#     # query = f"{req.question} ê´€ë ¨í•´ì„œ ì˜¤ëŠ˜ í•´ë³¼ ë§Œí•œ ë¯¸ì…˜ í•˜ë‚˜ ì¶”ì²œí•´ì¤˜."


#     # 1ï¸âƒ£ Intent ë¶„ë¥˜
#     try:
#         intent_res = requests.post(INTENT_API, json={"text": query}, timeout=2)
#         intent = intent_res.json().get("intent", "SPECIFIC")
#     except:
#         intent = "SPECIFIC"

#     # 2ï¸âƒ£ GENERALì´ë©´ user_dbì—ì„œ top3 ì¹´í…Œê³ ë¦¬ ìš”ì²­
#     if intent == "GENERAL":
#         try:
#             user_res = requests.post(USER_DB_API, json={"user_id": user_id}, timeout=2)
#             top3 = user_res.json().get("top3", [])
#             if top3:
#                 chosen = random.choice(top3)
#                 query = f"{chosen} {query}"
#         except:
#             pass  # ì‹¤íŒ¨í•˜ë©´ ê·¸ëŒ€ë¡œ ì§„í–‰
    
#     # ğŸ” RAG ê²€ìƒ‰
#     docs_with_scores = db.similarity_search_with_score(query, k=10)
#     print("ğŸ” ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼:")
#     for i, (doc, score) in enumerate(docs_with_scores):
#         content = doc.page_content or "(âš ï¸ ë‚´ìš© ì—†ìŒ)"
#         try:
#             preview = content[:100].replace('\n', ' ')
#         except Exception as e:
#             preview = f"(âš ï¸ ì¶œë ¥ ì‹¤íŒ¨: {e})"
#         print(f"  {i+1}. ì ìˆ˜: {score:.4f}")
#         print(f"     ìš”ì•½: {preview}")
#         print(f"     ì¶œì²˜: {doc.metadata.get('source', '(ì—†ìŒ)')}")
#     filtered_docs_with_scores = [(doc, score) for doc, score in docs_with_scores if score < 1.2]

#     if not filtered_docs_with_scores:
#         # âœ… fallback - CoT ë°©ì‹
#         prompt = (
#             "ë„ˆëŠ” ë¯¸ì…˜ ì¶”ì²œ AIì•¼. ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ê³ , JSON ì™¸ì—ëŠ” ì•„ë¬´ ê²ƒë„ ì¶œë ¥í•˜ì§€ ë§ˆ.\n"
#             'message í•­ëª©ì€ ì‚¬ìš©ìì˜ ìš”ì²­ì— ë§ëŠ” ì¹´í…Œê³ ë¦¬ë¥¼ ë¶„ì„í•˜ê³  ê·¸ ì¹´í…Œê³ ë¦¬ê°€ ì–´ë–¤ íŠ¹ì§•ê³¼ íš¨ê³¼ê°€ ìˆëŠ”ì§€ ì•Œë ¤ì£¼ê³  ê·¸ì— ë”°ë¥¸ ë¯¸ì…˜ì„ ì¶”ì²œí•´ì£¼ê³  ê·¸ê²Œ ì™œ ì¹´í…Œê³ ë¦¬ì˜ íŠ¹ì§•ì´ë‚˜ íš¨ê³¼ì™€ ê´€ë ¨ìˆëŠ”ì§€ ê·¼ê±°ë¥¼ ìì—°ìŠ¤ëŸ½ê³  ë¶€ë“œëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ë¯¸ì…˜ì¶”ì²œì¤˜."\n\n'
#             "category í•­ëª©ì€ í•´ë‹¹ ë¯¸ì…˜ì˜ ì¹´í…Œê³ ë¦¬ë¥¼ í•˜ë‚˜ë¡œ ìš”ì•½í•´ì„œ ë„£ì–´. (ì˜ˆ: ìš´ë™, ê°ì •ê´€ë¦¬, ìê¸°ê´€ë¦¬, ì§‘ì¤‘ ë“±)\n\n"
#             "ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´:\n"
#             '{\n'
#             '  "message": "ìì—°ì–´ ë¬¸ì¥ìœ¼ë¡œëœ ë¯¸ì…˜ì¶”ì²œ",\n'
#             '  "category": "ì¹´í…Œê³ ë¦¬"\n'
#             "}\n\n"
#             f"ì‚¬ìš©ì ìš”ì²­: {query}"
#         )
#     else:
#         # âœ… ì²« ë¬¸ì„œì—ì„œ ë³¸ë¬¸ í¬ë¡¤ë§
#         # 2. ì ìˆ˜ ì°¨ì´ê°€ ê±°ì˜ ì—†ë‹¤ë©´ ëœë¤ ì„ íƒ
#         if len(filtered_docs_with_scores) >= 2 and abs(filtered_docs_with_scores[0][1] - filtered_docs_with_scores[1][1]) < 0.03:
#             selected_doc = random.choice(filtered_docs_with_scores)[0]
#         else:
#             selected_doc = filtered_docs_with_scores[0][0]  # ìœ ì‚¬ë„ 1ë“± ë¬¸ì„œ
#         url = selected_doc.metadata.get("source")
#         blog_text = crawl_naver_blog(url) or ""
#         print(f"\nğŸŒ ì„ íƒëœ ë¬¸ì„œ URL: {url}")

#         blog_text = crawl_naver_blog(url) or ""
#         print(f"ğŸ“„ í¬ë¡¤ë§ëœ ë¸”ë¡œê·¸ ë³¸ë¬¸ ê¸¸ì´: {len(blog_text)}ì")
#         print(f"ğŸ“„ ë³¸ë¬¸ ì¼ë¶€:\n{blog_text[:500]}...\n")  # â† ì´ê²Œ í•µì‹¬!

#         prompt = (
#             "ë„ˆëŠ” ì‚¬ìš©ìì˜ ìš”ì²­ì„ ì°¸ê³  ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¯¸ì…˜ì„ ì¶”ì²œí•˜ëŠ” AIì•¼.\n"
#             "ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ê³ , JSON ì™¸ì—ëŠ” ì•„ë¬´ ê²ƒë„ ì¶œë ¥í•˜ì§€ ë§ˆ.\n\n"
#             "message í•­ëª©ì€ ì°¸ê³  ë¸”ë¡œê·¸ ë³¸ë¬¸ì˜ ë‚´ìš©ì„ ë³´ê³  ê·¸ê±¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì§€ ë§ê³  ì¹´í…Œê³ ë¦¬ì™€ ê´€ë ¨í•´ì„œ ì–´ë–¤ ê´€ë ¨ì´ ìˆê³ , ì–´ë–¤ ì¢…ë¥˜ê°€ ìˆê³ , ì–´ë–¤ íš¨ê³¼ë‚˜ ì˜í–¥ì´ ìˆëŠ”ì§€ ë§í•´ì•¼ í•˜ë©°, ì´ë¥¼ 4~5ì¤„ ì •ë„ ë˜ë„ë¡ ë°˜ë“œì‹œ ê¸¸ê³  ìì—°ìŠ¤ëŸ½ê³  ë¶€ë“œëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ë¯¸ì…˜ì„ ì¶”ì²œí•´ì•¼í•´. ë˜í•œ ì™œ ì¹´í…Œê³ ë¦¬ê°€ í•´ë‹¹ ë‹µë³€ì´ ì–´ë–¤ ê´€ë ¨ì´ ìˆëŠ”ì§€ ë¶„ì„ í›„ ë§í•˜ëŠ” ê²ƒë„ ìˆì–´ì•¼í•´.\n"
#             # 'ì˜ˆì‹œ: "ì±…ìƒ ì •ë¦¬ë¥¼ í•´ë³´ëŠ” ê±´ ì–´ë•Œìš”? ë§ˆìŒë„ í•¨ê»˜ ì •ë¦¬ë  ê±°ì˜ˆìš”."\n\n'
#             "ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´:\n"
#             '{\n'
#             '  "message": "ìì—°ì–´ ë¬¸ì¥ìœ¼ë¡œ ëœ ë¯¸ì…˜ì¶”ì²œ",\n'
#             '  "category": "ì¹´í…Œê³ ë¦¬"\n'
#             "}\n\n"
#             f"ì°¸ê³  ë¸”ë¡œê·¸ ë³¸ë¬¸:\n{blog_text[:3000]}\n\n"
#             f"ì‚¬ìš©ì ìš”ì²­: {query}"
#         )

#     # âœ… Groq API í˜¸ì¶œ
#     headers = {
#         "Authorization": f"Bearer {GROQ_API_KEY}",
#         "Content-Type": "application/json"
#     }
#     body = {
#         "model": "llama3-8b-8192",
#         "messages": [{"role": "user", "content": prompt}],
#         "temperature": 0.7
#     }

#     try:
#         response = requests.post(GROQ_API_URL, headers=headers, json=body)
#         result = response.json()
#         content = result["choices"][0]["message"]["content"]

#         json_match = re.search(r"\{.*\}", content, re.DOTALL)
#         if not json_match:
#             raise ValueError("ì‘ë‹µì—ì„œ JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

#         parsed = json.loads(json_match.group(0).replace("'", '"'))
#         parsed["response_time_sec"] = round(time.time() - start_time, 2)
#         return parsed

#     except Exception as e:
#         return JSONResponse(status_code=500, content={"error": str(e)})
    
@app.post("/recommend")
async def recommend(req: ChatRequest, request: Request):
    start_time = time.time()
    user_id = extract_user_id_from_token(request)
    query = f"{req.category} ê´€ë ¨í•´ì„œ ì˜¤ëŠ˜ í•´ë³¼ ë§Œí•œ ë¯¸ì…˜ í•˜ë‚˜ ì¶”ì²œí•´ì¤˜."

    # 1ï¸âƒ£ Intent ë¶„ë¥˜
    try:
        intent_res = requests.post(INTENT_API, json={"text": query}, timeout=2)
        intent = intent_res.json().get("intent", "SPECIFIC")
    except:
        intent = "SPECIFIC"

    # 2ï¸âƒ£ GENERALì´ë©´ user_dbì—ì„œ top3 ì¹´í…Œê³ ë¦¬ ìš”ì²­
    if intent == "GENERAL":
        try:
            user_res = requests.post(USER_DB_API, json={"user_id": user_id}, timeout=2)
            top3 = user_res.json().get("top3", [])
            if top3:
                chosen = random.choice(top3)
                query = f"{chosen} {query}"
        except:
            pass

    # ğŸ” RAG ê²€ìƒ‰
    docs_with_scores = db.similarity_search_with_score(query, k=10)
    filtered_docs_with_scores = [(doc, score) for doc, score in docs_with_scores if score < 1.2]

    # ğŸ“Œ Step 1 í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    if not filtered_docs_with_scores:
        step1_prompt = (
            f"ì‚¬ìš©ì ìš”ì²­: {query}\n\n"
            "ë„ˆëŠ” ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•´ ë¯¸ì…˜ì„ ì¶”ì²œí•˜ëŠ” AIì•¼. "
            "ë¨¼ì € ì¹´í…Œê³ ë¦¬ë¥¼ ë¶„ì„í•˜ê³ , ê·¸ ì¹´í…Œê³ ë¦¬ì˜ íš¨ê³¼ë‚˜ íŠ¹ì§•ì„ í•œ ì¤„ë¡œ ìš”ì•½í•œ í›„, "
            "ê·¸ì— ë§ëŠ” ë¯¸ì…˜ì„ 2ê°€ì§€ ì¶”ì²œí•´ì£¼ê³  ê·¸ê²Œ ì™œ ì¹´í…Œê³ ë¦¬ì˜ íš¨ê³¼ë‚˜ íŠ¹ì§•ê³¼ ë§ëŠ”ì§€ ê·¼ê±°ë¥¼ ë§í•´ì¤˜. "
            "ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë¶€ë“œëŸ½ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë§í•´ì¤˜."
        )
        url = "(ë¬¸ì„œ ì—†ìŒ)"
    else:
        if len(filtered_docs_with_scores) >= 2 and abs(filtered_docs_with_scores[0][1] - filtered_docs_with_scores[1][1]) < 0.03:
            selected_doc = random.choice(filtered_docs_with_scores)[0]
        else:
            selected_doc = filtered_docs_with_scores[0][0]
        url = selected_doc.metadata.get("source")
        blog_text = crawl_naver_blog(url) or ""

        # step1_prompt = (
        #     f"ì‚¬ìš©ì ìš”ì²­: {query}\n\n"
        #     f"ì°¸ê³  ë¸”ë¡œê·¸ ë³¸ë¬¸:\n{blog_text[:3000]}\n\n"
        #     "ë„ˆëŠ” ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•´ ë¯¸ì…˜ì„ ì¶”ì²œí•˜ëŠ” AIì•¼. "
        #     "ë¨¼ì € ì¹´í…Œê³ ë¦¬ë¥¼ ë¶„ì„í•˜ê³ , ê·¸ ì¹´í…Œê³ ë¦¬ì˜ íš¨ê³¼ë‚˜ íŠ¹ì§•ì„ í•œ ì¤„ë¡œ ìš”ì•½í•œ í›„, "
        #     "ìœ„ ë¸”ë¡œê·¸ ë³¸ë¬¸ì„ ì°¸ê³ í•´ì„œ ìì—°ìŠ¤ëŸ½ê³  ë¶€ë“œëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ë¯¸ì…˜ì„ 2ê°œ ì¶”ì²œí•´ì¤˜. "
        #     "ê° ë¯¸ì…˜ì´ ì™œ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì— ì ì ˆí•œì§€ ê·¼ê±°ë¥¼ ì„¤ëª…í•´ì¤˜. JSON í•„ìš” ì—†ê³  ìì—°ì–´ ë¬¸ì¥ìœ¼ë¡œ ë¬´ì¡°ê±´ í•œêµ­ì–´ë¡œ ì¤˜."
        # )
        step1_prompt = (
            f"ì‚¬ìš©ì ìš”ì²­: {query}\n\n"
            f"ì°¸ê³  ë¸”ë¡œê·¸ ë³¸ë¬¸:\n{blog_text[:3000]}\n\n"
            "ë„ˆëŠ” ë¸”ë¡œê·¸ ë³¸ë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ë¯¸ì…˜ì„ ì¶”ì²œí•˜ëŠ” AIì•¼. \n"
            "ë³¸ë¬¸ ë‚´ìš©ì„ ë°˜ë“œì‹œ ì°¸ê³ í•´ì„œ ê·¸ ì•ˆì˜ í•µì‹¬ ë¬¸ì¥ì´ë‚˜ í™œë™, í‚¤ì›Œë“œ ë“±ì„ ë¶„ì„í•˜ê³ , \n"
            "í•´ë‹¹ ë‚´ìš©ì„ ë°˜ì˜í•˜ì—¬ ë„ˆê°€ 2ê°œì˜ ë¯¸ì…˜ì„ ì°½ì‘í•˜ì—¬ ì¶”ì²œí•´ì¤˜. \n"
            "ë¯¸ì…˜ì€ ìì—°ìŠ¤ëŸ½ê³  ë¶€ë“œëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•˜ê³ , ì¶”ì²œ ì´ìœ ë„ ê°ê° ì ì–´ì¤˜. \n"
            "ì ˆëŒ€ë¡œ ë³¸ë¬¸ ë‚´ìš©ì„ ë¬´ì‹œí•˜ê±°ë‚˜ ì¼ë°˜ì ì¸ ì¶”ì²œë§Œ í•˜ì§€ ë§ˆ. ë°˜ë“œì‹œ ë³¸ë¬¸ ë‚´ìš©ì„ ë°˜ì˜í•´ì•¼ í•´.\n"
            "ê²°ê³¼ëŠ” ìì—°ì–´ í•œêµ­ì–´ ë¬¸ì¥ë§Œ ì œê³µí•´. JSONì€ í•„ìš” ì—†ì–´."
        )

    # âœ… Groq Step 1 - ìì—°ì–´ ë¬¸ì¥ ìƒì„±
    headers = {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type": "application/json"
    }

    step1_body = {
        "model": "llama3-8b-8192",
        "messages": [{"role": "user", "content": step1_prompt}],
        "temperature": 0.7
    }

    try:
        res1 = requests.post(GROQ_API_URL, headers=headers, json=step1_body)
        generated_text = res1.json()["choices"][0]["message"]["content"].strip()
        print("âœ… ìƒì„±ëœ ìì—°ì–´ ì¶”ì²œ ë¬¸ì¥:\n", generated_text)

        # âœ… Step 2: JSON ë³€í™˜ ìš”ì²­
        # step2_prompt = (
        #     f"ë‹¤ìŒ ë¬¸ì¥ì„ JSON í˜•ì‹ìœ¼ë¡œ ë°”ê¿”ì¤˜.\n"
        #     "messageì—ëŠ” ì´ ë¬¸ì¥ì„ ë„£ëŠ”ë° ë”°ì˜´í‘œ(`\"`)ë¥¼ í¬í•¨í•˜ì§€ ë§ê³ , categoryì—ëŠ” ì ì ˆí•œ í•˜ë‚˜ì˜ ì¹´í…Œê³ ë¦¬ë§Œ ë„£ì–´ì¤˜. "
        #     "ê·¸ë¦¬ê³  titleì—ëŠ” ì´ messageë¥¼ í•œë§ˆë””ë¡œ ìš”ì•½í•´ì„œ ë„£ì–´ì¤˜. ê·¸ë¦¬ê³  message,category,titleì€ ì „ë¶€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ í•´ì•¼í•˜ê³ ,"
        #     "ë¬´ì¡°ê±´ ì¶œë ¥ê²°ê³¼ë¬¼ì€ ë°‘ì˜ í˜•ì‹ìœ¼ë¡œ jsonë§Œ ìˆì–´ì•¼ ë¼."
        #     '{\n'
        #     '  "message": "...",\n'
        #     '  "category": "...",\n'
        #     '  "title": "..." \n'
        #     '}\n\n'
        #     f"ë¬¸ì¥: {generated_text}"
        # )
        step2_prompt = (
            f"ë‹¤ìŒ ë¬¸ì¥ì„ JSONìœ¼ë¡œ ë°”ê¿”ì¤˜. ì ˆëŒ€ë¡œ í°ë”°ì˜´í‘œ(`\"`) ì•ˆì— ë˜ ë‹¤ë¥¸ í°ë”°ì˜´í‘œê°€ ë“¤ì–´ê°€ë©´ ì•ˆ ë¼. \n"
            "message í•­ëª©ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ í‘œí˜„í•˜ê³ , í°ë”°ì˜´í‘œëŠ” í•„ìš”í•  ê²½ìš° ì‘ì€ë”°ì˜´í‘œë‚˜ ì„¤ëª…ì‹ìœ¼ë¡œ ë°”ê¿”. \n"
            "ì¶œë ¥ì€ ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì²˜ëŸ¼ JSONë§Œ:\n"
            '{\n'
            '  "message": "í•œêµ­ì–´ë¡œ ëœ ë¯¸ì…˜ ì¶”ì²œ ë¬¸ì¥",\n'
            '  "category": "ì¹´í…Œê³ ë¦¬ëª…",\n'
            '  "title": "ì§§ì€ ìš”ì•½ ì œëª©"\n'
            '}\n\n'
            f"ë¬¸ì¥: {generated_text}"
        )

        step2_body = {
            "model": "llama3-8b-8192",
            "messages": [{"role": "user", "content": step2_prompt}],
            "temperature": 0.3
        }

        res2 = requests.post(GROQ_API_URL, headers=headers, json=step2_body)
        result = res2.json()
        content = result["choices"][0]["message"]["content"]
        print("ğŸ“¦ Groq ì‘ë‹µ ì›ë¬¸:\n", content)

        json_match = re.search(r"\{.*\}", content, re.DOTALL)
        if not json_match:
            raise ValueError("ì‘ë‹µì—ì„œ JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        raw_json = json_match.group(0).replace("'", '"')
        print("ğŸ“¦ ì¶”ì¶œëœ JSON ë¬¸ìì—´:\n", raw_json)

        parsed = json.loads(raw_json)
        parsed["source"] = url
        parsed["response_time_sec"] = round(time.time() - start_time, 2)
        return parsed

    except Exception as e:
        print("âŒ ì˜ˆì™¸ ë°œìƒ:", e)
        return JSONResponse(status_code=500, content={
            "error": str(e),
            "raw_groq_response": content if 'content' in locals() else "ì‘ë‹µ ì—†ìŒ"
        })



# âœ… ë””ë²„ê¹…ìš© ë¬¸ì„œ í™•ì¸ìš© API
@app.get("/documents")
async def get_documents():
    try:
        data = db.get()
        documents_info = []
        for i in range(len(data["ids"])):
            doc = {
                "id": data["ids"][i],
                "document": data["documents"][i],
                "metadata": data["metadatas"][i]
            }
            documents_info.append(doc)
        return JSONResponse(content={"documents": documents_info})
    except Exception as e:
        return JSONResponse(status_code=500, content={"error": str(e)})
    
